# IVIE_FM

åŒºé—´å€¼æ¨¡ç³Šç§¯åˆ†ç¥ç»ç½‘ç»œ - FMå®ç°ç‰ˆæœ¬

## æ¨¡å—ç»“æ„

```
IVIE_FM/
â”œâ”€â”€ __init__.py          # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ ivie.py              # IEç½‘ç»œä¸»ç±»
â”œâ”€â”€ iv_loss.py           # æŸå¤±å‡½æ•°
â”œâ”€â”€ narray_op.py         # åŒºé—´è¿ç®—
â”œâ”€â”€ feature_layer.py     # ç‰¹å¾ç»„åˆå±‚
â””â”€â”€ README.md
```

## å¿«é€Ÿä½¿ç”¨

```python
from IVIE_FM.ivie import IE
from IVIE_FM.iv_loss import HausdorffIntervalLoss

# åˆ›å»ºæ¨¡å‹
model = IE(
    feature_size=7,              # ç‰¹å¾æ•°é‡
    additivity_order=2,          # äº¤äº’é˜¶æ•° (æ¨è2-3)
    op='Algebraic_interval',     # åŒºé—´è¿ç®—ç±»å‹
    device='cuda'
)

# è®­ç»ƒ
criterion = HausdorffIntervalLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
model.fit_and_valid(train_loader, test_loader, criterion, optimizer, epochs=100)

# é¢„æµ‹
pred_l, pred_u = model(X_test)
```

## æ ¸å¿ƒç»„ä»¶

### 1. IE ç½‘ç»œä¸»ç±» (`ivie.py`)

**å‚æ•°è¯´æ˜**:
- `feature_size`: ç‰¹å¾æ•°é‡
- `additivity_order`: ç‰¹å¾äº¤äº’æœ€å¤§é˜¶æ•°ï¼ˆå»ºè®®2-3ï¼Œé¿å…æ•°å€¼ä¸‹æº¢ï¼‰
- `op`: åŒºé—´è¿ç®—ç±»å‹
  - `'Algebraic_interval'`: ä»£æ•°ç§¯è¿ç®—
  - `'Min_interval'`: æœ€å°T-normè¿ç®—
- `alpha`, `beta`: Min_intervalçš„æ’åºå‚æ•°
- `device`: è®¡ç®—è®¾å¤‡ ('cuda' æˆ– 'cpu')

**è¾“å…¥æ ¼å¼**: `[x1_l, x2_l, ..., xn_l, x1_u, x2_u, ..., xn_u]`  
**è¾“å‡ºæ ¼å¼**: `(ä¸‹ç•Œå¼ é‡, ä¸Šç•Œå¼ é‡)`

### 2. åŒºé—´è¿ç®— (`narray_op.py`)

#### Algebraic_interval - ä»£æ•°ç§¯è¿ç®—
- è®¡ç®—æ‰€æœ‰ç‰¹å¾ç»„åˆçš„ä»£æ•°ç§¯
- åŒºé—´[a,b] Ã— [c,d] = [ac, bd]

#### Min_interval - æœ€å°T-normè¿ç®—
- åŸºäºalpha-betaå‚æ•°é€‰æ‹©æœ€å°åŒºé—´
- é€‰æ‹©è§„åˆ™: v = (1-Î±)Â·l + Î±Â·u

### 3. ç‰¹å¾çŸ©é˜µ (`feature_layer.py`)

**FeatureMatrix** - æ„å»ºChoquetç§¯åˆ†æ‰€éœ€çš„ç¨€ç–01çŸ©é˜µ
- å½¢çŠ¶: (2^n - 1, 2 Ã— (2^n - 1))
- ç”¨äºç‰¹å¾ç»„åˆçš„æƒé‡è®¡ç®—

### 4. æŸå¤±å‡½æ•° (`iv_loss.py`)

#### interval_loss - åŸºç¡€æŸå¤±
- åŸºäºHausdorffè·ç¦»

#### ImprovedIntervalLoss - æ¨èä½¿ç”¨
- ç«¯ç‚¹MSEæŸå¤± + åŒºé—´æœ‰æ•ˆæ€§æƒ©ç½š + å®½åº¦åŒ¹é…
- å‚æ•°: `validity_weight=0.1`, `width_weight=0.05`

#### HausdorffIntervalLoss - Hausdorffè·ç¦»
- æœ€å¤§ç«¯ç‚¹è¯¯å·®è·ç¦»
- å‚æ•°: `validity_weight=0.1`

## æ•°æ®æµç¨‹

```
è¾“å…¥ [xl1,...,xln,xu1,...,xun]
    â†“
ç‰¹å¾ç»„åˆå±‚ (narray_op)
    â†“
ç‰¹å¾çŸ©é˜µå˜æ¢ (feature_layer)
    â†“
æ¨¡ç³Šæµ‹åº¦åŠ æƒ (FMå±‚)
    â†“
IVIEç§¯åˆ†è®¡ç®—
    â†“
è¾“å‡º (ä¸‹ç•Œ, ä¸Šç•Œ)
```

## è®­ç»ƒç¤ºä¾‹

```python
from IVIE_FM.iv_loss import ImprovedIntervalLoss

# é…ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-5)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)

# ä½¿ç”¨å†…ç½®è®­ç»ƒæ–¹æ³•
criterion = ImprovedIntervalLoss(validity_weight=0.1, width_weight=0.05)
model.fit_and_valid(train_loader, test_loader, criterion, optimizer, epochs=100)
```

## æœ€ä½³å®è·µ

### å‚æ•°é€‰æ‹©å»ºè®®

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| additivity_order | 2-3 | é¿å…é«˜é˜¶ç‰¹å¾ç»„åˆå¯¼è‡´æ•°å€¼ä¸‹æº¢ |
| op | Algebraic_interval | è¿ç»­å¯å¯¼ï¼Œä¾¿äºä¼˜åŒ– |
| learning_rate | 0.001-0.005 | é…åˆå­¦ä¹ ç‡è°ƒåº¦å™¨ |
| batch_size | 32-64 | æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´ |



---


## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
import torch
from IVIE.ivie import IE

# åˆ›å»ºæ¨¡å‹ (æ¨èé…ç½®)
model = IE(
    feature_size=7,            # 7 ä¸ªç‰¹å¾
    additivity_order=2,        # åªè€ƒè™‘2é˜¶äº¤äº’ï¼Œé¿å…æ•°å€¼é—®é¢˜
    op='Algebraic_interval',   # ä½¿ç”¨ä»£æ•°åŒºé—´è¿ç®—
    alpha=0.5,
    beta=0,
    device='cuda'
)
model = model.to('cuda')

# å‡†å¤‡åŒºé—´å€¼è¾“å…¥ [å·¦ç«¯ç‚¹ä»¬, å³ç«¯ç‚¹ä»¬]
# å½¢çŠ¶: (batch_size, 2 * n_features)
x = torch.rand(32, 14).to('cuda')  # 32 ä¸ªæ ·æœ¬ï¼Œ7 ä¸ªç‰¹å¾çš„åŒºé—´å€¼

# å‰å‘ä¼ æ’­
pred_left, pred_right = model(x)
print(f"é¢„æµ‹åŒºé—´å½¢çŠ¶: {pred_left.shape}, {pred_right.shape}")  # (32, 1), (32, 1)
```



### å¿«é€Ÿè®­ç»ƒ (ä½¿ç”¨å†…ç½®æ–¹æ³•)

```python
# ä½¿ç”¨æ¨¡å‹å†…ç½®çš„è®­ç»ƒæ–¹æ³•
from IVIE.iv_loss import interval_loss as IntervalLoss

criterion = IntervalLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

model.fit_and_valid(
    train_Loader=train_loader,
    test_Loader=test_loader,
    criterion=criterion,
    optimizer=optimizer,
    device=device,
    epochs=100
)
```
## æ€§èƒ½è°ƒä¼˜å»ºè®®

### 1. è®­ç»ƒç­–ç•¥

âœ… **ä½¿ç”¨æ—©åœ**:
```python
patience = 30
best_val_loss = float('inf')
patience_counter = 0

# åœ¨è®­ç»ƒå¾ªç¯ä¸­
if avg_val_loss < best_val_loss:
    best_val_loss = avg_val_loss
    patience_counter = 0
    torch.save(model.state_dict(), 'best_model.pth')
else:
    patience_counter += 1
    if patience_counter >= patience:
        break
```

âœ… **æ‰¹é‡å¤§å°**:
- å°æ•°æ®é›† (< 1000): batch_size = 16-32
- ä¸­ç­‰æ•°æ®é›† (1000-10000): batch_size = 32-64
- å¤§æ•°æ®é›† (> 10000): batch_size = 64-128

âœ… **è®­ç»ƒè½®æ•°**:
- é…åˆæ—©åœ: epochs = 300-500
- æ— æ—©åœ: epochs = 100-200

### 2. æ¨¡å‹åˆå§‹åŒ–

å½“å‰æ¨¡å‹ä½¿ç”¨å‡åŒ€åˆå§‹åŒ–ã€‚å¯ä»¥å°è¯•æ”¹è¿›:

```python
# åœ¨ IE.__init__ ä¸­ä¿®æ”¹
# é»˜è®¤: dummy = (1./self.columns_num) * torch.ones((self.nVars, 1))
# æ”¹è¿›: ä½¿ç”¨ Xavier åˆå§‹åŒ–
import torch.nn as nn
init_val = torch.empty((self.nVars, 1))
nn.init.xavier_uniform_(init_val)
init_val = torch.abs(init_val) * 0.5 + 0.1  # ä¿è¯æ­£å€¼
self.vars = torch.nn.Parameter(init_val)
```

### 3. ç›‘æ§æŒ‡æ ‡

å»ºè®®åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§:
- è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±
- åŒºé—´æœ‰æ•ˆæ€§ (é¢„æµ‹çš„ä¸‹ç•Œ â‰¤ ä¸Šç•Œçš„æ¯”ä¾‹)
- å¹³å‡ç»å¯¹è¯¯å·® (MAE): `torch.mean(torch.abs(pred_l - true_l) + torch.abs(pred_u - true_u))`
- åŒºé—´å®½åº¦: `torch.mean(pred_u - pred_l)`

---

## ç‰ˆæœ¬å†å²

### v1.1.0 (2026å¹´1æœˆ)
- âœ¨ æ–°å¢ `additivity_order` æ”¯æŒï¼Œè§£å†³é«˜é˜¶ç»„åˆçš„æ•°å€¼ä¸‹æº¢é—®é¢˜
- âœ¨ æ–°å¢ `ImprovedIntervalLoss` å’Œ `HausdorffIntervalLoss` æŸå¤±å‡½æ•°
- ğŸ”§ ä¼˜åŒ– `forward` æ–¹æ³•ï¼Œæ­£ç¡®å¤„ç†å—é™é˜¶æ•°çš„ç‰¹å¾çŸ©é˜µ
- ğŸ”§ ä¼˜åŒ– `ivie_nn_vars` æ–¹æ³•ï¼Œæ”¯æŒå—é™é˜¶æ•°çš„æ¨¡ç³Šæµ‹åº¦æ„å»º
- ğŸ“ å®Œå–„æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- ğŸ¯ æå‡åœ¨UCIç­‰å®é™…æ•°æ®é›†ä¸Šçš„æ€§èƒ½

### v1.0.0 (åˆå§‹ç‰ˆæœ¬)
- åŸºç¡€IEç½‘ç»œå®ç°
- æ”¯æŒ Algebraic_interval å’Œ Min_interval æ“ä½œ
- åŸºç¡€æŸå¤±å‡½æ•° interval_loss

---

**æœ€åæ›´æ–°**: 2026å¹´1æœˆ14æ—¥
